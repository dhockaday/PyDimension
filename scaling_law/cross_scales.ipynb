{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross scales experiments for pip flow\n",
    "\n",
    "- **Authors**: Xiaoyu Xie\n",
    "- **Contact**: xiaoyuxie2020@u.northwestern.edu\n",
    "- **Date**: May, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import matrix_rank\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "import pysindy as ps\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.optimize import minimize\n",
    "import xgboost\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mu    l    v    rho        p           Re data_source\n",
      "0  0.0045  0.6  292  0.004  40000.0   155.733333       Train\n",
      "1  0.0010  0.4  377  0.003  50000.0   452.400000       Train\n",
      "2  0.0088  0.7  572  0.009  20000.0   409.500000       Train\n",
      "3  0.0040  0.8  274  0.009  20000.0   493.200000       Train\n",
      "4  0.0038  0.9  877  0.005  40000.0  1038.552632       Train\n",
      "Re_min, Re_max 0 6675.749999999999\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "param_list = ['mu', 'l', 'v', 'rho', 'p', 'Re']\n",
    "train_num, test_num = 100, 100\n",
    "\n",
    "# training set: small l\n",
    "res = []\n",
    "Re_min, Re_max = 0, 0\n",
    "for _ in range(train_num):\n",
    "    mu = np.random.randint(1, 100) / 1e4\n",
    "    l = np.random.randint(1, 10) / 10\n",
    "    v = np.random.randint(100, 1000)\n",
    "    rho = np.random.randint(1, 10) / 1e3\n",
    "    p = np.random.randint(1, 10) * 1e4\n",
    "    Re  = rho * v * l / mu\n",
    "    if Re < Re_min: \n",
    "        Re_min = Re\n",
    "    if Re > Re_max: \n",
    "        Re_max = Re\n",
    "    res.append([mu, l, v, rho, p, Re, 'Train'])\n",
    "\n",
    "# test set: large l\n",
    "while True:\n",
    "    mu = np.random.randint(1, 100) / 1e5\n",
    "    l = np.random.randint(100, 1000) / 10 # large l\n",
    "    v = np.random.randint(1, 10)\n",
    "    rho = np.random.randint(1, 10) / 1e4\n",
    "    p = np.random.randint(1, 10) * 1e4\n",
    "    Re  = rho * v * l / mu\n",
    "    \n",
    "    if Re < Re_min or Re > Re_max:\n",
    "        continue\n",
    "    res.append([mu, l, v, rho, p, Re, 'Test'])\n",
    "    if len(res) >= test_num + train_num:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame(res, columns=['mu', 'l', 'v', 'rho', 'p', 'Re', 'data_source'])\n",
    "print(df.head())\n",
    "print('Re_min, Re_max', Re_min, Re_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu</th>\n",
       "      <th>l</th>\n",
       "      <th>v</th>\n",
       "      <th>rho</th>\n",
       "      <th>p</th>\n",
       "      <th>Re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>558.750000</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>50400.000000</td>\n",
       "      <td>462.776547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.245567</td>\n",
       "      <td>246.118038</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>26243.613942</td>\n",
       "      <td>924.212221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>341.250000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>68.403846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>554.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>162.686499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>777.750000</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>462.272973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>90000.000000</td>\n",
       "      <td>6675.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mu           l           v         rho             p  \\\n",
       "count  100.000000  100.000000  100.000000  100.000000    100.000000   \n",
       "mean     0.005335    0.470000  558.750000    0.004960  50400.000000   \n",
       "std      0.002612    0.245567  246.118038    0.002723  26243.613942   \n",
       "min      0.000400    0.100000  113.000000    0.001000  10000.000000   \n",
       "25%      0.003200    0.300000  341.250000    0.003000  30000.000000   \n",
       "50%      0.005400    0.500000  554.000000    0.005000  50000.000000   \n",
       "75%      0.007300    0.700000  777.750000    0.007250  70000.000000   \n",
       "max      0.009700    0.900000  999.000000    0.009000  90000.000000   \n",
       "\n",
       "                Re  \n",
       "count   100.000000  \n",
       "mean    462.776547  \n",
       "std     924.212221  \n",
       "min       7.000000  \n",
       "25%      68.403846  \n",
       "50%     162.686499  \n",
       "75%     462.272973  \n",
       "max    6675.750000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_val set\n",
    "df_train_val =  df[df['data_source']=='Train']\n",
    "data_train_val = df_train_val[['mu', 'l', 'v', 'rho', 'p', 'Re']].to_numpy()\n",
    "\n",
    "# test set\n",
    "df_test =  df[df['data_source']=='Test']\n",
    "data_test = df_test[['mu', 'l', 'v', 'rho', 'p', 'Re']].to_numpy()\n",
    "\n",
    "# add gaussian noise\n",
    "noise_level = 0.0\n",
    "for i in range(data_train_val.shape[1]):\n",
    "    data_train_val[:, i] += noise_level * np.std(data_train_val[:, i]) * np.random.randn(train_num,)\n",
    "    data_test[:, i] += noise_level * np.std(data_test[:, i]) * np.random.randn(test_num,)\n",
    "\n",
    "# split input and output\n",
    "X_train_val = data_train_val[:, :-1]\n",
    "y_train_val = data_train_val[:, -1].reshape(-1,1)\n",
    "X_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1].reshape(-1,1)\n",
    "\n",
    "# noisy df\n",
    "df_train_noise = pd.DataFrame(data_train_val, columns=['mu', 'l', 'v', 'rho', 'p', 'Re'])\n",
    "df_train_noise.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionlessLearning(object):\n",
    "    '''\n",
    "    Indentify the explicit form one coefficient using dimensionless learning\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, df, input_list, output_coef, dimension_info, basis_list):\n",
    "        super(DimensionlessLearning, self).__init__()\n",
    "        self.df = df\n",
    "        self.input_list = input_list\n",
    "        self.output_coef = output_coef\n",
    "        self.X, self.y = self.prepare_dataset()\n",
    "        self.dimension_info, self.basis_list = dimension_info, basis_list\n",
    "        self.basis1_in, self.basis2_in = self.prepare_dimension()\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        '''\n",
    "        prepare the input and output data\n",
    "        '''\n",
    "        X = self.df[self.input_list].to_numpy()\n",
    "        y = self.df[self.output_coef].to_numpy().reshape(-1, 1)\n",
    "        return X, y\n",
    "        \n",
    "    def prepare_dimension(self):\n",
    "        '''\n",
    "        parse dimension for input and output\n",
    "        '''\n",
    "        basis1_in, basis2_in = self.basis_list[0], self.basis_list[1]\n",
    "        return basis1_in, basis2_in\n",
    "\n",
    "    def fetch_coef_pi(self, coef):\n",
    "        '''\n",
    "        parse the combined weights for the input\n",
    "        '''\n",
    "        coef_pi = coef[0] * self.basis1_in + coef[1] * self.basis2_in\n",
    "        return coef_pi\n",
    "        \n",
    "    def check_dimension(self, coef):\n",
    "        '''\n",
    "        check whether the basis vectors can formulated as the D_out\n",
    "        '''\n",
    "        coef_pi = self.fetch_coef_pi(coef)\n",
    "        # print('[check] coef_pi: \\n', coef_pi)\n",
    "        target_D_out = np.dot(self.dimension_info[0], coef_pi)\n",
    "        # print('[check] target_D_out: \\n', target_D_out)\n",
    "        assert np.array_equal(target_D_out, self.dimension_info[1]), 'Wrong target_D_out!'\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict\n",
    "        '''\n",
    "        pi_in = np.prod(np.power(X, self.gamma.reshape(-1,)), axis=1).reshape(-1, 1)\n",
    "        pred = pi_in * self.beta\n",
    "        return pred\n",
    "\n",
    "    def fit_pattern_search(self, seed):\n",
    "        '''\n",
    "        pattern search\n",
    "        '''\n",
    "        def get_coordinates(a, b, delta):\n",
    "            '''\n",
    "            Build a list to store all possible coordiantes\n",
    "            '''\n",
    "            coord_all = []\n",
    "            for a_ in [a-delta, a, a+delta]:\n",
    "                for b_ in [b-delta, b, b+delta]:\n",
    "                    if [a_, b_] != [a, b]:\n",
    "                        coord_all.append([a_, b_])\n",
    "            return coord_all\n",
    "        \n",
    "        def opt(coef):\n",
    "            '''\n",
    "            fit a linear regression\n",
    "            '''\n",
    "            coef_pi = self.fetch_coef_pi(coef)\n",
    "            pi_in = np.prod(np.power(self.X, coef_pi.reshape(-1,)), axis=1).reshape(-1, 1)\n",
    "            reg =LinearRegression(fit_intercept=False)\n",
    "            reg.fit(pi_in, self.y)\n",
    "            y_pred = reg.predict(pi_in)\n",
    "            r2 = r2_score(self.y, y_pred)\n",
    "            return r2, coef_pi, reg.coef_\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        res, break_points = [], []\n",
    "        a = np.random.choice(np.linspace(-2, 2, 9), 1)[0]  # [-2, 2] delta=0.5\n",
    "        b = np.random.choice(np.linspace(-2, 2, 9), 1)[0]  # [-2, 2] delta=0.5\n",
    "        coef = np.array([a, b]).reshape(-1, 1)\n",
    "\n",
    "        iter_num, max_iter, delta = 0, 10, 0.5\n",
    "        while iter_num < max_iter:\n",
    "            candidate_coord = get_coordinates(a, b, delta)\n",
    "            r2_center, reg_coef_center, coef_w_center = opt(coef)\n",
    "            # print('r2_center', round(r2_center, 2), 'reg_coef_center', [round(each, 2) for each in list(reg_coef_center.reshape(-1,))])\n",
    "            # print('coef_w_center', coef_w_center)\n",
    "\n",
    "            if r2_center < 0.2:\n",
    "                break_points.append([a, b])\n",
    "                break\n",
    "\n",
    "            r2_bounds_val = []\n",
    "            for [a_, b_] in candidate_coord:\n",
    "                coef_temp = np.array([a_, b_]).reshape(-1, 1)\n",
    "                r2_bound, reg_coef_bound, coef_w_bound = opt(coef_temp)\n",
    "                r2_bounds_val.append(r2_bound)\n",
    "\n",
    "            # sort r2 from high to low\n",
    "            highest_index = np.argsort(r2_bounds_val)[::-1][0]\n",
    "            iter_num += 1\n",
    "\n",
    "            # udpate the center coordiantes when the R2 in the neighborhood is higher\n",
    "            if r2_center < r2_bounds_val[highest_index]:\n",
    "                [a, b] = candidate_coord[highest_index]\n",
    "                coef = np.array([a, b]).reshape(-1, 1)\n",
    "                coef_pi = self.fetch_coef_pi(coef)\n",
    "                res_info = {'a': a, 'b': b, 'r2_center': round(r2_bounds_val[highest_index], 4)}\n",
    "                # print('update', res_info)\n",
    "                res.append(res_info)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        coef_pi = self.fetch_coef_pi(coef)\n",
    "        r2, reg_coef_final, coef_w_final = opt(coef)\n",
    "        self.gamma, self.beta = reg_coef_final, int(round(coef_w_final[0][0], 0))\n",
    "\n",
    "        return r2, reg_coef_final, coef_w_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_train: 1.0000, r2_val: 1.0000, r2_test: 1.0000\n",
      "r2_train: 1.0000, r2_val: 1.0000, r2_test: 1.0000\n",
      "r2_train: 1.0000, r2_val: 1.0000, r2_test: 1.0000\n",
      "r2_train: 1.0000, r2_val: 1.0000, r2_test: 1.0000\n",
      "r2_train: 1.0000, r2_val: 1.0000, r2_test: 1.0000\n",
      "               model_name Train  Val Test\n",
      "0  dimensionless_learning   1.0  1.0  1.0\n",
      "1  dimensionless_learning   1.0  1.0  1.0\n",
      "2  dimensionless_learning   1.0  1.0  1.0\n",
      "3  dimensionless_learning   1.0  1.0  1.0\n",
      "4  dimensionless_learning   1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# Dimensionless learning\n",
    "input_list = ['mu', 'l', 'v', 'rho', 'p']\n",
    "output_coef = 'Re'\n",
    "\n",
    "D_in = np.mat('-1, -1, 1; 1, 0, 0; 1, -1, 0; -3, 0, 1; -1, -2, 1').T\n",
    "D_out = np.mat('0;, 0; 0')\n",
    "dimension_info = [D_in, D_out]\n",
    "\n",
    "basis1_in = np.array([-1, 1, 1, 1, 0]).reshape(-1, 1)\n",
    "basis2_in = np.array([-1, 1, -1, 0, 1]).reshape(-1, 1)\n",
    "basis_list = [basis1_in, basis2_in]\n",
    "\n",
    "# cross-validation\n",
    "model_name_list = ['dimensionless_learning'] * 5\n",
    "r2_train_list, r2_val_list, r2_tes_list = [], [], []\n",
    "# ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "ss = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "for train_index, val_index in ss.split(data_train_val):\n",
    "\n",
    "    X_train, y_train = data_train_val[train_index, :-1], data_train_val[train_index, -1].reshape(-1, 1)\n",
    "    X_val, y_val = data_train_val[val_index, :-1], data_train_val[val_index, -1].reshape(-1, 1)\n",
    "    df_train_temp = pd.DataFrame(data_train_val, columns=['mu', 'l', 'v', 'rho', 'p', 'Re'])\n",
    "\n",
    "    for seed in range(5):\n",
    "        dimensionless_learning = DimensionlessLearning(df_train_temp, input_list, output_coef, dimension_info, basis_list)\n",
    "        r2, coef, coef_w = dimensionless_learning.fit_pattern_search(seed=seed)\n",
    "        if r2 < 0.8:\n",
    "            continue\n",
    "        # print('final r2', r2, coef.flatten(), coef_w)\n",
    "        y_train_pred = dimensionless_learning.predict(X_train)\n",
    "        y_val_pred = dimensionless_learning.predict(X_val)\n",
    "        y_test_pred = dimensionless_learning.predict(X_test)\n",
    "        r2_train, r2_val, r2_test = r2_score(y_train, y_train_pred), r2_score(y_val, y_val_pred), r2_score(y_test, y_test_pred)\n",
    "        print(f'r2_train: {r2_train:.4f}, r2_val: {r2_val:.4f}, r2_test: {r2_test:.4f}')\n",
    "        r2_train_list.append(r2_train), r2_val_list.append(r2_val), r2_tes_list.append(r2_test)\n",
    "        break\n",
    "\n",
    "df_dimension = pd.DataFrame(np.array([model_name_list, r2_train_list, r2_val_list, r2_tes_list]).T, columns=['model_name', 'Train', 'Val', 'Test'])\n",
    "print(df_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_val_transformed = scaler.fit_transform(X_train_val)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "y_train_val_transformed = scaler.fit_transform(y_train_val)\n",
    "y_test_transformed = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(model_name, para_grids):\n",
    "    '''\n",
    "    Cross-validation and evaluate on the test set\n",
    "    '''\n",
    "    # GridSearchCV to search the best parameters for the model\n",
    "    estimator = eval(f'{model_name}()')\n",
    "    grid = GridSearchCV(estimator, para_grids, scoring='r2', cv=5)\n",
    "    grid.fit(X_train_val_transformed, y_train_val_transformed)\n",
    "    # best_model = grid.best_estimator_\n",
    "    print(f'model_name: {model_name}')\n",
    "    print(f'best_params:{grid.best_params_}')\n",
    "    model_name_list = [model_name] * 5\n",
    "\n",
    "    # cross-validation\n",
    "    # ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    ss = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    r2_train_list, r2_val_list, r2_tes_list = [], [], []\n",
    "    for train_index, val_index in ss.split(X_train_val_transformed):\n",
    "        model = eval(f'{model_name}(**grid.best_params_)')\n",
    "        X_train, y_train = X_train_val_transformed[train_index, :], y_train_val_transformed[train_index]\n",
    "        X_val, y_val = X_train_val_transformed[val_index, :], y_train_val_transformed[val_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        r2_train, r2_val, r2_test = model.score(X_train, y_train), model.score(X_val, y_val), model.score(X_test_transformed, y_test_transformed)\n",
    "        print(f'r2_train: {r2_train:.4f}, r2_val: {r2_val:.4f}, r2_test: {r2_test:.4f}')\n",
    "        r2_train_list.append(r2_train), r2_val_list.append(r2_val), r2_tes_list.append(r2_test)\n",
    "\n",
    "    df = pd.DataFrame(np.array([model_name_list, r2_train_list, r2_val_list, r2_tes_list]).T, columns=['model_name', 'Train', 'Val', 'Test'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: model_name, value: para_grids\n",
    "configs = {\n",
    "    'LinearRegression': {},\n",
    "    'xgboost.XGBRegressor': {\n",
    "        'n_estimators': [20, 50, 80], \n",
    "        'max_depth': [5, 10, 20],\n",
    "        'seed': [0],\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'n_estimators' : [10, 50, 100, 200], \n",
    "        'max_features' : ['auto', 'log2', 'sqrt'], \n",
    "        'bootstrap' : [True, False], \n",
    "        'random_state': [0]\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'n_neighbors': [2, 3, 4, 5],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'hidden_layer_sizes': [(100, 100, 100), (50, 100, 50)], \n",
    "        'alpha': [0.00005, 0.0005],\n",
    "        'max_iter': [200, 500, 800],\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "        'random_state': [0],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: LinearRegression\n",
      "best_params:{}\n",
      "r2_train: 0.5795, r2_val: 0.3579, r2_test: -4806.4307\n",
      "r2_train: 0.4846, r2_val: 0.5539, r2_test: -4165.5951\n",
      "r2_train: 0.5216, r2_val: -0.4441, r2_test: -4273.3456\n",
      "r2_train: 0.5218, r2_val: -2.4113, r2_test: -4526.2871\n",
      "r2_train: 0.4463, r2_val: 0.5926, r2_test: -1681.6184\n",
      "model_name: xgboost.XGBRegressor\n",
      "best_params:{'max_depth': 5, 'n_estimators': 20, 'seed': 0}\n",
      "r2_train: 0.9989, r2_val: 0.6572, r2_test: -3.5887\n",
      "r2_train: 0.9986, r2_val: 0.8858, r2_test: -4.7738\n",
      "r2_train: 0.9986, r2_val: -6.8117, r2_test: -7.3723\n",
      "r2_train: 0.9990, r2_val: 0.6682, r2_test: -0.1385\n",
      "r2_train: 0.9987, r2_val: 0.5682, r2_test: -0.3198\n",
      "model_name: RandomForestRegressor\n",
      "best_params:{'bootstrap': True, 'max_features': 'log2', 'n_estimators': 50, 'random_state': 0}\n",
      "r2_train: 0.9598, r2_val: 0.4355, r2_test: -1.2620\n",
      "r2_train: 0.9169, r2_val: 0.8328, r2_test: -3.5448\n",
      "r2_train: 0.9492, r2_val: -1.1425, r2_test: -2.1319\n",
      "r2_train: 0.9232, r2_val: 0.3504, r2_test: -3.9884\n",
      "r2_train: 0.9015, r2_val: 0.4521, r2_test: -0.8882\n",
      "model_name: KNeighborsRegressor\n",
      "best_params:{'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "r2_train: 0.5795, r2_val: 0.2885, r2_test: -1.7152\n",
      "r2_train: 0.5438, r2_val: 0.3044, r2_test: -0.9803\n",
      "r2_train: 0.5395, r2_val: 0.7173, r2_test: -1.1356\n",
      "r2_train: 0.5478, r2_val: 0.6223, r2_test: -1.6572\n",
      "r2_train: 0.4758, r2_val: 0.5147, r2_test: -0.0160\n",
      "model_name: MLPRegressor\n",
      "best_params:{'alpha': 0.0005, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'max_iter': 200, 'random_state': 0}\n",
      "r2_train: 0.9968, r2_val: 0.5143, r2_test: -7006.4066\n",
      "r2_train: 0.9988, r2_val: 0.5482, r2_test: -8867.2314\n",
      "r2_train: 0.9991, r2_val: 0.1623, r2_test: -26856.3159\n",
      "r2_train: 0.9993, r2_val: 0.8097, r2_test: -12370.9716\n",
      "r2_train: 0.9993, r2_val: 0.7119, r2_test: -5617.2697\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.579519</td>\n",
       "      <td>0.357872</td>\n",
       "      <td>-4806.430687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.484566</td>\n",
       "      <td>0.553903</td>\n",
       "      <td>-4165.595128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.521640</td>\n",
       "      <td>-0.444123</td>\n",
       "      <td>-4273.345576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.521824</td>\n",
       "      <td>-2.411334</td>\n",
       "      <td>-4526.287068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.446318</td>\n",
       "      <td>0.592597</td>\n",
       "      <td>-1681.618358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_name     Train       Val         Test\n",
       "0  LinearRegression  0.579519  0.357872 -4806.430687\n",
       "1  LinearRegression  0.484566  0.553903 -4165.595128\n",
       "2  LinearRegression  0.521640 -0.444123 -4273.345576\n",
       "3  LinearRegression  0.521824 -2.411334 -4526.287068\n",
       "4  LinearRegression  0.446318  0.592597 -1681.618358"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine different models' results\n",
    "res = []\n",
    "for model_name, para_grids in configs.items():\n",
    "    res_each = train_eval(model_name, para_grids)\n",
    "    res.append(res_each)\n",
    "res.append(df_dimension)\n",
    "res_all = pd.concat(res)\n",
    "res_all = res_all.astype({'Train': 'float64', 'Val': 'float64', 'Test': 'float64'})\n",
    "res_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_map = {\n",
    "    'dimensionless_learning': 'Proposed \\nmethod',\n",
    "    'RandomForestRegressor': 'RF',\n",
    "    'MLPRegressor': 'FFNN',\n",
    "    'LinearRegression': 'LR',\n",
    "    'KNeighborsRegressor': 'KNN',\n",
    "    'xgboost.XGBRegressor': 'XGBoost',\n",
    "}\n",
    "\n",
    "res_final = []\n",
    "for i in range(res_all.shape[0]):\n",
    "    each_row = res_all.iloc[i]\n",
    "    model_name = model_name_map[each_row['model_name']]\n",
    "    res_final.append([model_name, float(each_row['Train']), 'Training set'])\n",
    "    res_final.append([model_name, float(each_row['Val']), 'Validation set'])\n",
    "    res_final.append([model_name, float(each_row['Test']), 'Test set'])\n",
    "\n",
    "df_final = pd.DataFrame(res_final, columns=['Model_name', 'R2', 'Data source'])\n",
    "df_final.head()\n",
    "df_final.to_csv('../results/cross_material.csv')\n",
    "df_final = pd.read_csv('../results/cross_material.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "sns.barplot(data=df_final, x='Model_name', y='R2', hue='Data source')\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.legend(fontsize=14, loc=4)\n",
    "plt.xlabel('Model name', fontsize=18)\n",
    "plt.ylabel(r'$R^2$', fontsize=18)\n",
    "plt.tick_params(labelsize=13)\n",
    "plt.savefig('../results/cross_scales.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4e05679d6a31593988b5489bd865ca5a262d5481eb276cba948c252ea078b95"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('xie')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
