{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import pysindy as ps\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import yaml\n",
    "\n",
    "from utils.PolyDiff import PolyDiffPoint\n",
    "from utils.SeqReg import SeqReg\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitEqu(object):\n",
    "    '''\n",
    "    Sparse regression to fit a equation\n",
    "\n",
    "    1. create dataset\n",
    "    2. preprocess dataset\n",
    "    3. build library\n",
    "    4. fit equation\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(FitEqu, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset(case_id):\n",
    "        '''\n",
    "        load dataset\n",
    "        '''\n",
    "        U = np.load(f'/mnt/data/dataset/three_cylinder/dataset/NS-equ/{case_id}/u_3D.npy')\n",
    "        V = np.load(f'/mnt/data/dataset/three_cylinder/dataset/NS-equ/{case_id}/v_3D.npy')\n",
    "        P = np.load(f'/mnt/data/dataset/three_cylinder/dataset/NS-equ/{case_id}/p_3D.npy')\n",
    "\n",
    "        P = np.transpose(P, axes=[2, 1, 0])\n",
    "        U = np.transpose(U, axes=[2, 1, 0])\n",
    "        V = np.transpose(V, axes=[2, 1, 0])\n",
    "\n",
    "        return U, V, P\n",
    "    \n",
    "    @staticmethod\n",
    "    def select_sub_domain(U, V, P, x_range, y_range):\n",
    "        '''\n",
    "        select a sub-domain\n",
    "        '''\n",
    "        # select a sub-domain\n",
    "        U = U[x_range[0]:x_range[1], y_range[0]:y_range[1], :]\n",
    "        V = V[x_range[0]:x_range[1], y_range[0]:y_range[1], :]\n",
    "        P = P[x_range[0]:x_range[1], y_range[0]:y_range[1], :]            \n",
    "        return U, V, P\n",
    "    \n",
    "    @staticmethod\n",
    "    def non_dimensionlize(U, V, P, dx, dy, dt, ref_params, sim_params):\n",
    "        '''\n",
    "        non-dimensionlize dx, dy, and dt\n",
    "        '''\n",
    "        # reference parameters\n",
    "        l_ref, v_ref, p_ref = ref_params['l_ref'], ref_params['v_ref'], ref_params['p_ref'] \n",
    "        t_ref, w_ref = l_ref / v_ref, v_ref / l_ref\n",
    "\n",
    "        # non-dimensionlize data\n",
    "        U, V, P = U/v_ref, V/v_ref, P/p_ref\n",
    "        dx, dy, dt = dx / l_ref, dy / l_ref, dt / t_ref\n",
    "\n",
    "        # analyze the dimensionless numbers\n",
    "        Re = v_ref * l_ref * sim_params['rho'] / sim_params['mu']\n",
    "        Fr = ref_params['v_ref'] / float(np.sqrt(sim_params['g'] * ref_params['l_ref']))\n",
    "        Eu = ref_params['p_ref'] / (sim_params['rho'] * ref_params['v_ref']**2)\n",
    "        pi_group = {'Re': Re, 'Fr': Fr, 'Eu': Eu}\n",
    "        print(colored(f'Re: {int(Re)}, coef_best: {round(1 / Re, 6)}', 'red'))\n",
    "        print(colored(f'Eu: {int(Eu)}, coef_best: {round(Eu, 6)}', 'red'))\n",
    "        # print(colored(f'Fr: {int(Fr)}, coef_best: {round(1/Fr/Fr, 6)}', 'red'))\n",
    "        return U, V, P, dx, dy, dt, pi_group\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_points(Nx, Ny, boundary_x, boundary_y, boundary_t):\n",
    "        '''\n",
    "        sample a certain number of points to train\n",
    "        '''\n",
    "        np.random.seed(0)\n",
    "        points, count = {}, 0\n",
    "        num_xy = 500\n",
    "        for _ in range(num_xy):\n",
    "            x = np.random.choice(np.arange(boundary_x, Nx-boundary_x), 1)[0]\n",
    "            y = np.random.choice(np.arange(boundary_y, Ny-boundary_y), 1)[0]\n",
    "            for t in range(10, 100, 10):\n",
    "                points[count] = [x, y, t]\n",
    "                count = count + 1\n",
    "        return points\n",
    "\n",
    "    @staticmethod\n",
    "    def cal_derivatives(U, V, P, points, boundary_x, boundary_y, boundary_t, dx, dy, dt, deg=5):\n",
    "        num_points = len(points)\n",
    "        p = np.zeros((num_points,1))\n",
    "        u = np.zeros((num_points,1))\n",
    "        v = np.zeros((num_points,1))\n",
    "        ut, vt = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
    "        ux, vx = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
    "        uy, vy = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
    "        uxx, vxx = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
    "        uxy, vxy = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
    "        uyy, vyy = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
    "        px, py = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
    "\n",
    "        Nx_sample, Ny_sample, Nt_sample = 2*boundary_x-1, 2*boundary_y-1, 2*boundary_t-1\n",
    "\n",
    "        for idx_p in tqdm(points.keys()):\n",
    "            [x, y, t] = points[idx_p]\n",
    "            u[idx_p] = U[x, y, t]\n",
    "            v[idx_p] = V[x, y, t]\n",
    "            p[idx_p] = P[x, y, t]\n",
    "            \n",
    "            ut_part = U[x, y, t-int((Nt_sample-1)/2):t+int((Nt_sample+1)/2)]\n",
    "            ux_part = U[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y, t]\n",
    "            uy_part = U[x, y-int((Ny_sample-1)/2):y+int((Ny_sample+1)/2), t]\n",
    "            ux_part_yp = U[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y+1, t]\n",
    "            ux_part_ym = U[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y-1, t]\n",
    "\n",
    "            vt_part = V[x, y, t-int((Nt_sample-1)/2):t+int((Nt_sample+1)/2)]\n",
    "            vx_part = V[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y, t]\n",
    "            vy_part = V[x, y-int((Ny_sample-1)/2):y+int((Ny_sample+1)/2), t]\n",
    "            vx_part_yp = V[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y+1, t]\n",
    "            vx_part_ym = V[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y-1, t]\n",
    "\n",
    "            px_part = P[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y, t]\n",
    "            py_part = P[x, y-int((Ny_sample-1)/2):y+int((Ny_sample+1)/2), t]\n",
    "\n",
    "            ut[idx_p] = PolyDiffPoint(ut_part, np.arange(Nt_sample)*dt, deg, 1)[0]\n",
    "            ux_diff = PolyDiffPoint(ux_part, np.arange(Nx_sample)*dx, deg, 2)\n",
    "            uy_diff = PolyDiffPoint(uy_part, np.arange(Ny_sample)*dy, deg, 2)\n",
    "            ux_diff_yp = PolyDiffPoint(ux_part_yp, np.arange(Nx_sample)*dx, deg, 2)\n",
    "            ux_diff_ym = PolyDiffPoint(ux_part_ym, np.arange(Nx_sample)*dx, deg, 2)\n",
    "\n",
    "            vt[idx_p] = PolyDiffPoint(vt_part, np.arange(Nt_sample)*dt, deg, 1)[0]\n",
    "            vx_diff = PolyDiffPoint(vx_part, np.arange(Nx_sample)*dx, deg, 2)\n",
    "            vy_diff = PolyDiffPoint(vy_part, np.arange(Ny_sample)*dy, deg, 2)\n",
    "            vx_diff_yp = PolyDiffPoint(vx_part_yp, np.arange(Nx_sample)*dx, deg, 2)\n",
    "            vx_diff_ym = PolyDiffPoint(vx_part_ym, np.arange(Nx_sample)*dx, deg, 2)\n",
    "\n",
    "            ux[idx_p], uxx[idx_p] = ux_diff[0], ux_diff[1]\n",
    "            uy[idx_p], uyy[idx_p] = uy_diff[0], uy_diff[1]\n",
    "            uxy[idx_p] = (ux_diff_yp[0] - ux_diff_ym[0]) / (2 * dy)\n",
    "\n",
    "            vx[idx_p], vxx[idx_p] = vx_diff[0], vx_diff[1]\n",
    "            vy[idx_p], vyy[idx_p] = vy_diff[0], vy_diff[1]\n",
    "            vxy[idx_p] = (vx_diff_yp[0] - vx_diff_ym[0]) / (2 * dy)\n",
    "\n",
    "            px[idx_p] = PolyDiffPoint(px_part, np.arange(Nx_sample)*dx, deg, 1)[0]\n",
    "            py[idx_p] = PolyDiffPoint(py_part, np.arange(Ny_sample)*dy, deg, 1)[0]\n",
    "        \n",
    "        base_library = [u, v, p, ut, ux, uy, uxx, uxy, uyy, vt, vx, vy, vxx, vxy, vyy, px, py]\n",
    "        return base_library\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_library(base_library, sim_params, ref_params):\n",
    "        '''\n",
    "        calculate derivatives and build library for sparse regression\n",
    "        '''\n",
    "        u, v, p, ut, ux, uy, uxx, uxy, uyy, vt, vx, vy, vxx, vxy, vyy, px, py = base_library\n",
    "        g_x = np.zeros_like(u)\n",
    "        g_y = np.ones_like(u) * sim_params['g'] * ref_params['l_ref'] / ref_params['v_ref']**2\n",
    "        # ########################standard sindy library#########################\n",
    "        # X_library = [u*ux, v*uy, uxx, uyy, px]\n",
    "        # names = ['u*ux', 'v*uy', 'uxx', 'uyy', 'px']\n",
    "\n",
    "        # #########################rotationial invariance#########################\n",
    "        ########################## More terms (6 terms in total, 4 independent terms)##########################\n",
    "        ut_ = np.concatenate([ut+vt, vt+ut])\n",
    "        u_ = np.concatenate([u+v, v+u])\n",
    "        uu_ = np.concatenate([u*(u+v), v*(v+u)])\n",
    "        vu_ = np.concatenate([v*(u+v), u*(v+u)])\n",
    "\n",
    "        ux_ = np.concatenate([ux+vx, vy+uy])\n",
    "        uy_ = np.concatenate([uy+vy, vx+ux])\n",
    "        uxx_ = np.concatenate([uxx+vxx, vyy+uyy])\n",
    "        uyy_ = np.concatenate([uyy+vyy, vxx+uxx])\n",
    "\n",
    "        uux_ = np.concatenate([u*(ux+vx), v*(vy+uy)])\n",
    "        uuy_ = np.concatenate([u*(uy+vy), v*(vx+ux)])\n",
    "        uuxx_ = np.concatenate([u*(uxx+vxx), v*(vyy+vyy)])\n",
    "        uuyy_ = np.concatenate([u*(uyy+vyy), v*(vxx+uxx)])\n",
    "\n",
    "        vux_ = np.concatenate([v*(ux+vx), u*(vy+uy)])\n",
    "        vuy_ = np.concatenate([v*(uy+vy), u*(vx+ux)])\n",
    "        vuxx_ = np.concatenate([v*(uxx+vxx), u*(vyy+vyy)])\n",
    "        vuyy_ = np.concatenate([v*(uyy+vyy), u*(vxx+uxx)])\n",
    "\n",
    "        uuxx_ = np.concatenate([u*(uxx+vxx), v*(vyy+vyy)])\n",
    "        uuyy_ = np.concatenate([u*(uyy+vyy), v*(vxx+uxx)])\n",
    "        vuxx_ = np.concatenate([v*(uxx+vxx), u*(vyy+vyy)])\n",
    "        vuyy_ = np.concatenate([v*(uyy+vyy), u*(vxx+uxx)])\n",
    "        \n",
    "        p_ = np.concatenate([p, p])\n",
    "        px_ = np.concatenate([px+py, py+px])\n",
    "\n",
    "        ut, u, uu, vu, ux, uy, uxx, uyy = ut_, u_, uu_, vu_, ux_, uy_, uxx_, uyy_\n",
    "        uux, uuy, uuxx, uuyy, vux, vuy, vuxx, vuyy, px = uux_, uuy_, uuxx_, uuyy_, vux_, vuy_, vuxx_, vuyy_, px_\n",
    "        p = p_\n",
    "\n",
    "        # term and position: (uux: 7, vuy: 12, uxx: 5, uyy: 6, px: 16)\n",
    "        X_library = [\n",
    "            u, uu, vu, ux, uy, \n",
    "            uxx, uyy, uux, uuy, uuxx, \n",
    "            uuyy, vux, vuy, vuxx, vuyy, \n",
    "            p, px]\n",
    "        names = ['u', 'uu', 'vu', 'ux', 'uy', 'uxx', 'uyy', 'uux', \n",
    "                'uuy', 'uuxx', 'uuyy', 'vux', 'vuy', 'vuxx', 'vuyy', 'p', 'px']\n",
    "        \n",
    "        # X_library = [uux, vuy, uxx, uyy, px]\n",
    "        # names = ['uux', 'vuy', 'uxx', 'uyy', 'px']\n",
    "        ##########################Reshape data##########################\n",
    "        X_library = np.squeeze(np.stack(X_library, axis=-1))\n",
    "        y_library = ut.reshape(-1, 1)\n",
    "\n",
    "        return X_library, y_library, names\n",
    "\n",
    "    @staticmethod\n",
    "    def normalization(X_library, y_library):\n",
    "        '''\n",
    "        Rescale the data by each column\n",
    "        rescale the data by the absolute mean for each column\n",
    "        '''\n",
    "        norm_coef = np.mean(np.abs(np.mean(X_library, axis=0)))\n",
    "        X_library = X_library / norm_coef\n",
    "        y_library = y_library / norm_coef\n",
    "        return X_library, y_library, norm_coef\n",
    "\n",
    "    @staticmethod\n",
    "    def check_library(X_library, y_library):\n",
    "        '''\n",
    "        check whether the library has any Nan\n",
    "        '''\n",
    "        if np.any(np.isnan(X_library)) or np.any(np.isnan(y_library)):\n",
    "            print('Nan exists in library.')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def check_equ(X_library, y_library, pi_group):\n",
    "        '''\n",
    "        check the r2 for the target equation\n",
    "        '''\n",
    "        # pred_best = - X_library[:, 0] - X_library[:, 1]\\\n",
    "        #             + 1/pi_group['Re'] * (X_library[:, 2] + X_library[:, 3]) \\\n",
    "        #             - X_library[:, 4] * pi_group['Eu']\n",
    "        pred_best = - X_library[:, 7] - X_library[:, 12]\\\n",
    "                    + 1/pi_group['Re'] * (X_library[:, 5] + X_library[:, 6]) \\\n",
    "                    - X_library[:, 16] * pi_group['Eu']\n",
    "        pred_best = pred_best.reshape(-1,1)\n",
    "        r2 = r2_score(y_library, pred_best)\n",
    "        print(f\"Analytical r2_score: {round(r2, 6)}\")\n",
    "\n",
    "        # pred_best = - X_library[:, 0] - X_library[:, 1]\\\n",
    "        #             - X_library[:, 4] * pi_group['Eu']\n",
    "        pred_best = - X_library[:, 7] - X_library[:, 12]\\\n",
    "                    - X_library[:, 16] * pi_group['Eu']\n",
    "        pred_best = pred_best.reshape(-1,1)\n",
    "        r2_2 = r2_score(y_library, pred_best)\n",
    "        print(f\"Analytical r2_score (no 1/Re): {round(r2_2, 6)}\")\n",
    "        print('difference', r2-r2_2)\n",
    "        return None\n",
    "        \n",
    "    @staticmethod\n",
    "    def fit(X_library, y_library, threshold=0.002):\n",
    "        '''\n",
    "        squential threshold with dynamic threshold\n",
    "        '''\n",
    "        model = SeqReg()\n",
    "        coef, _, r2 = model.fit_dynamic_thresh(X_library, y_library, \n",
    "                        is_normalize=False, non_zero_term=5, threshold=threshold, fit_intercept=False, model_name='LR')\n",
    "        print('Fitting r2', r2)\n",
    "        return coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** v2-Re-100\n",
      "\u001b[31mRe: 100, coef_best: 0.01\u001b[0m\n",
      "\u001b[31mEu: 14545, coef_best: 14545.454545\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [00:09<00:00, 485.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical r2_score: 0.977453\n",
      "Analytical r2_score (no 1/Re): -0.4572\n",
      "difference 1.4346528029232668\n",
      "Fitting r2 0.9847303326884334\n",
      "\u001b[31mcoef_res: [('px', -14127.228361), ('uux', -0.975949), ('vuy', -0.975949), ('uxx', 0.010526), ('uyy', 0.010526)]\u001b[0m\n",
      "**************************************** v1-Re-170\n",
      "\u001b[31mRe: 170, coef_best: 0.005882\u001b[0m\n",
      "\u001b[31mEu: 3897, coef_best: 3897.626183\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [00:10<00:00, 441.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical r2_score: 0.996039\n",
      "Analytical r2_score (no 1/Re): 0.87458\n",
      "difference 0.12145844970686415\n",
      "Fitting r2 0.9971417409241901\n",
      "\u001b[31mcoef_res: [('px', -3850.279219), ('uux', -0.981435), ('vuy', -0.981435), ('uxx', 0.006257), ('uyy', 0.006257)]\u001b[0m\n",
      "**************************************** v3-Re-200\n",
      "\u001b[31mRe: 200, coef_best: 0.005\u001b[0m\n",
      "\u001b[31mEu: 3019, coef_best: 3019.973003\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [00:11<00:00, 395.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical r2_score: 0.990589\n",
      "Analytical r2_score (no 1/Re): 0.910358\n",
      "difference 0.08023132146766032\n",
      "Fitting r2 0.9933591045175174\n",
      "\u001b[31mcoef_res: [('px', -2977.747494), ('uux', -0.981976), ('vuy', -0.981976), ('uxx', 0.005887), ('uyy', 0.005887)]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config_path = 'configs/config_NS_3cylinder_clean.yml'\n",
    "\n",
    "config = yaml.load(open(config_path, 'r'), Loader=yaml.FullLoader)\n",
    "case_id_list = list(config['case_id_list'].keys())\n",
    "\n",
    "def prepare_dataset(is_show=False):\n",
    "    '''\n",
    "    prepare a sets of dataset\n",
    "    '''\n",
    "    res = []\n",
    "    fit_equ = FitEqu()\n",
    "\n",
    "    for case_id in case_id_list:\n",
    "        print('*' * 40, case_id)\n",
    "        case_info = config['case_id_list'][case_id]\n",
    "        Nx, Ny = 500, 222\n",
    "        dx, dy = 0.9/Nx, 0.4/Ny\n",
    "\n",
    "        ref_params = case_info['ref_params']\n",
    "        sim_params = case_info['sim_params']\n",
    "        sim_params['niu'] = sim_params['mu'] / sim_params['rho']\n",
    "        dt = sim_params['dt']\n",
    "\n",
    "        # parameters for sparse regression\n",
    "        x_range, y_range = case_info['x_range'], case_info['y_range']\n",
    "        boundary_x, boundary_y, boundary_t = case_info['fitting']['boundary_num']  # default is 5\n",
    "        deg = case_info['fitting']['deg']               # polynomial degree default is 3\n",
    "        \n",
    "        #####################Prepare Dataset#####################\n",
    "        # generate data and save to a folder\n",
    "        U, V, W = fit_equ.load_dataset(case_id)\n",
    "        U, V, W = fit_equ.select_sub_domain(U, V, W, x_range, y_range)\n",
    "        # non-dimensionlize data and dx, dy, dt\n",
    "        U, V, W, dx, dy, dt, pi_group = fit_equ.non_dimensionlize(U, V, W, dx, dy, dt, ref_params, sim_params)\n",
    "        Nx, Ny, Nt = W.shape\n",
    "        # sample points\n",
    "        points = fit_equ.sample_points(Nx, Ny, boundary_x, boundary_y, boundary_t)        \n",
    "        # plot the 1st frame \n",
    "        # if is_show: fig = plt.figure(figsize=(6, 4)); plt.imshow(V[:, :, 0].T)\n",
    "        \n",
    "        #####################Prepare library#####################\n",
    "        base_library = fit_equ.cal_derivatives(\n",
    "            U, V, W, points, boundary_x, boundary_y, boundary_t, dx, dy, dt, deg)\n",
    "        X_library, y_library, names = fit_equ.parse_library(base_library, sim_params, ref_params)\n",
    "        X_library, y_library, norm_coef = fit_equ.normalization(X_library, y_library)\n",
    "        # check data\n",
    "        is_nan = fit_equ.check_library(X_library, y_library)\n",
    "        if is_nan: continue\n",
    "        df_all = pd.DataFrame(np.concatenate([X_library, y_library], axis=1))\n",
    "        # check the fitting of the target equation\n",
    "        fit_equ.check_equ(X_library, y_library, pi_group)\n",
    "        # visualization library\n",
    "        # if is_show: fig = plt.figure(); df_all.plot(); plt.xlim([0, 2000])\n",
    "        # print(df_all.describe())\n",
    "        # df_all.to_csv('../results/test_dataset_NS_flow3D.csv')\n",
    "\n",
    "        #####################Fit sequential sparse regression#####################\n",
    "        coef = fit_equ.fit(X_library, y_library)\n",
    "        # coef = np.multiply(norm_coef, coef)\n",
    "        # print('rescale coef', coef)\n",
    "        coef_res = [(each[0], round(each[1], 6)) for each in list(zip(names, coef.tolist())) if abs(each[1]) > 1e-3]\n",
    "        coef_res = sorted(coef_res, key=lambda x: abs(x[1]), reverse=True)\n",
    "        print(colored(f'coef_res: {coef_res}', 'red'))\n",
    "        # add to the total results\n",
    "        res.append([sim_params['niu'], ref_params['l_ref'], ref_params['v_ref'], ref_params['p_ref'],\n",
    "                sim_params['rho'], sim_params['g'], pi_group['Re'], pi_group['Eu'], pi_group['Fr']] + coef.tolist())\n",
    "        # break\n",
    "\n",
    "    df = pd.DataFrame(res)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = prepare_dataset(True)\n",
    "df.to_csv('../dataset/dataset_NS_flow3D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/dataset_NS_flow3D.csv')\n",
    "df = df.rename(columns={\n",
    "    '0': 'nu',\n",
    "    '1': 'diameter',\n",
    "    '2': 'v_init',\n",
    "    '3': 'p_init',\n",
    "    '4': 'density',\n",
    "    '5': 'g',\n",
    "    '6': 'Re',\n",
    "    '7': 'Eu',\n",
    "    '8': 'Fr',\n",
    "    })\n",
    "df['mu'] = df['nu'] * df['density']\n",
    "df['1/Re'] = 1/ df['Re']\n",
    "# print(df.head())\n",
    "df.to_csv('../dataset/dataset_NS_flow3D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Re</th>\n",
       "      <th>1/Re</th>\n",
       "      <th>14</th>\n",
       "      <th>Eu</th>\n",
       "      <th>25</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>14545.454545</td>\n",
       "      <td>-14127.228361</td>\n",
       "      <td>-0.975949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170.003185</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.006257</td>\n",
       "      <td>3897.626183</td>\n",
       "      <td>-3850.279219</td>\n",
       "      <td>-0.981435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200.004618</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>3019.973003</td>\n",
       "      <td>-2977.747494</td>\n",
       "      <td>-0.981976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Re      1/Re        14            Eu            25        21\n",
       "0  100.000000  0.010000  0.010526  14545.454545 -14127.228361 -0.975949\n",
       "1  170.003185  0.005882  0.006257   3897.626183  -3850.279219 -0.981435\n",
       "2  200.004618  0.005000  0.005887   3019.973003  -2977.747494 -0.981976"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Re', '1/Re', '14', 'Eu', '25', '21']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final r2 0.9232367560249745 [-5.   5.   0.   2.5  2.5] [[0.]]\n",
      "final r2 0.976187545349888 [ 1. -1. -1. -1.  0.] [[1.07458988]]\n",
      "final r2 0.9947425794295909 [-1.5  1.5 -0.5  0.5  1. ] [[0.]]\n",
      "final r2 0.976187545349888 [ 1. -1. -1. -1.  0.] [[1.07458988]]\n",
      "final r2 0.9947425794295909 [-1.5  1.5 -0.5  0.5  1. ] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "class DimensionlessLearning(object):\n",
    "    '''\n",
    "    Indentify the explicit form one coefficient using dimensionless learning\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, df, input_list, output_coef, dimension_info, basis_list):\n",
    "        super(DimensionlessLearning, self).__init__()\n",
    "        self.df = df\n",
    "        self.input_list = input_list\n",
    "        self.output_coef = output_coef\n",
    "        self.X, self.y = self.prepare_dataset()\n",
    "        self.dimension_info, self.basis_list = dimension_info, basis_list\n",
    "        self.basis1_in, self.basis2_in = self.prepare_dimension()\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        '''\n",
    "        prepare the input and output data\n",
    "        '''\n",
    "        X = self.df[self.input_list].to_numpy()\n",
    "        y = self.df[self.output_coef].to_numpy().reshape(-1, 1)\n",
    "        return X, y\n",
    "        \n",
    "    def prepare_dimension(self):\n",
    "        '''\n",
    "        parse dimension for input and output\n",
    "        '''\n",
    "        basis1_in, basis2_in = self.basis_list[0], self.basis_list[1]\n",
    "        return basis1_in, basis2_in\n",
    "\n",
    "    def fetch_coef_pi(self, coef):\n",
    "        '''\n",
    "        parse the combined weights for the input\n",
    "        '''\n",
    "        coef_pi = coef[0] * self.basis1_in + coef[1] * self.basis2_in\n",
    "        return coef_pi\n",
    "        \n",
    "    def check_dimension(self, coef):\n",
    "        '''\n",
    "        check whether the basis vectors can formulated as the D_out\n",
    "        '''\n",
    "        coef_pi = self.fetch_coef_pi(coef)\n",
    "        # print('[check] coef_pi: \\n', coef_pi)\n",
    "        target_D_out = np.dot(self.dimension_info[0], coef_pi)\n",
    "        # print('[check] target_D_out: \\n', target_D_out)\n",
    "        assert np.array_equal(target_D_out, self.dimension_info[1]), 'Wrong target_D_out!'\n",
    "\n",
    "    def fit_pattern_search(self, seed):\n",
    "        '''\n",
    "        pattern search\n",
    "        '''\n",
    "        def get_coordinates(a, b, delta):\n",
    "            '''\n",
    "            Build a list to store all possible coordiantes\n",
    "            '''\n",
    "            coord_all = []\n",
    "            for a_ in [a-delta, a, a+delta]:\n",
    "                for b_ in [b-delta, b, b+delta]:\n",
    "                    if [a_, b_] != [a, b]:\n",
    "                        coord_all.append([a_, b_])\n",
    "            return coord_all\n",
    "        \n",
    "        def opt(coef):\n",
    "            '''\n",
    "            fit a linear regression\n",
    "            '''\n",
    "            coef_pi = self.fetch_coef_pi(coef)\n",
    "            pi_in = np.prod(np.power(self.X, coef_pi.reshape(-1,)), axis=1).reshape(-1, 1)\n",
    "            reg =LinearRegression(fit_intercept=False)\n",
    "            reg.fit(pi_in, self.y)\n",
    "            y_pred = reg.predict(pi_in)\n",
    "            r2 = r2_score(self.y, y_pred)\n",
    "            return r2, coef_pi, reg.coef_\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        res, break_points = [], []\n",
    "        a = np.random.choice(np.linspace(-2, 2, 9), 1)[0]  # [-2, 2] delta=0.5\n",
    "        b = np.random.choice(np.linspace(-2, 2, 9), 1)[0]  # [-2, 2] delta=0.5\n",
    "        # a, b = -1, 0\n",
    "        coef = np.array([a, b]).reshape(-1, 1)\n",
    "\n",
    "        iter_num, max_iter, delta = 0, 10, 0.5\n",
    "        while iter_num < max_iter:\n",
    "            candidate_coord = get_coordinates(a, b, delta)\n",
    "            r2_center, reg_coef_center, coef_w_center = opt(coef)\n",
    "            # print('r2_center', round(r2_center, 2), 'reg_coef_center', [round(each, 2) for each in list(reg_coef_center.reshape(-1,))])\n",
    "            # print('coef_w_center', coef_w_center)\n",
    "\n",
    "            if r2_center < 0.2:\n",
    "                break_points.append([a, b])\n",
    "                break\n",
    "            \n",
    "            r2_bounds_val = []\n",
    "            for [a_, b_] in candidate_coord:\n",
    "                coef_temp = np.array([a_, b_]).reshape(-1, 1)\n",
    "                r2_bound, reg_coef_bound, coef_w_bound = opt(coef_temp)\n",
    "                r2_bounds_val.append(r2_bound)\n",
    "\n",
    "            # sort r2 from high to low\n",
    "            highest_index = np.argsort(r2_bounds_val)[::-1][0]\n",
    "            iter_num += 1\n",
    "\n",
    "            # udpate the center coordiantes when the R2 in the neighborhood is higher\n",
    "            if r2_center < r2_bounds_val[highest_index]:\n",
    "                [a, b] = candidate_coord[highest_index]\n",
    "                coef = np.array([a, b]).reshape(-1, 1)\n",
    "                coef_pi = self.fetch_coef_pi(coef)\n",
    "                res_info = {'a': a, 'b': b, 'r2_center': round(r2_bounds_val[highest_index], 4)}\n",
    "                # print('update', res_info)\n",
    "                res.append(res_info)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        coef_pi = self.fetch_coef_pi(coef)\n",
    "        r2, reg_coef_final, coef_w_final = opt(coef)\n",
    "        return r2, reg_coef_final, coef_w_final\n",
    "\n",
    "\n",
    "def recover_coef1(seed):\n",
    "    input_list = ['mu', 'diameter', 'v_init', 'density', 'p_init']\n",
    "    output_coef = '14'  # for 1/Re\n",
    "\n",
    "    D_in = np.mat('-1, -1, 1; 1, 0, 0; 1, -1, 0; -3, 0, 1; -1, -2, 1').T\n",
    "    D_out = np.mat('0;, 0; 0')\n",
    "    dimension_info = [D_in, D_out]\n",
    "\n",
    "    basis1_in = np.array([-1, 1, 1, 1, 0]).reshape(-1, 1)\n",
    "    basis2_in = np.array([-1, 1, -1, 0, 1]).reshape(-1, 1)\n",
    "    basis_list = [basis1_in, basis2_in]\n",
    "    \n",
    "    dimensionless_learning = DimensionlessLearning(\n",
    "        df, input_list, output_coef, dimension_info, basis_list)\n",
    "    # dimensionless_learning.check_dimension(coef=[-1, 1])\n",
    "\n",
    "    # pattern search\n",
    "    r2, coef, coef_w = dimensionless_learning.fit_pattern_search(seed=seed)\n",
    "    if r2 > 0.8:\n",
    "        print('final r2', r2, coef.flatten(), coef_w)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    recover_coef1(seed=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final r2 0.9972789966395783 [-2.5  2.5 -1.5  0.5  2. ] [[-0.]]\n",
      "final r2 0.9972789966395783 [-2.5  2.5 -1.5  0.5  2. ] [[-0.]]\n",
      "final r2 0.9999279037590756 [ 0.  0. -2. -1.  1.] [[-0.9728875]]\n",
      "final r2 0.9999279037590756 [ 0.  0. -2. -1.  1.] [[-0.9728875]]\n",
      "final r2 0.9999279037590756 [ 0.  0. -2. -1.  1.] [[-0.9728875]]\n",
      "final r2 0.9999279037590756 [ 0.  0. -2. -1.  1.] [[-0.9728875]]\n",
      "final r2 0.9972789966395783 [-2.5  2.5 -1.5  0.5  2. ] [[-0.]]\n"
     ]
    }
   ],
   "source": [
    "def recover_coef1(seed):\n",
    "    input_list = ['mu', 'diameter', 'v_init', 'density', 'p_init']\n",
    "    output_coef = '25'  # for Eu\n",
    "\n",
    "    D_in = np.mat('-1, -1, 1; 1, 0, 0; 1, -1, 0; -3, 0, 1; -1, -2, 1').T\n",
    "    D_out = np.mat('0;, 0; 0')\n",
    "    dimension_info = [D_in, D_out]\n",
    "\n",
    "    basis1_in = np.array([-1, 1, 1, 1, 0]).reshape(-1, 1)\n",
    "    basis2_in = np.array([-1, 1, -1, 0, 1]).reshape(-1, 1)\n",
    "    basis_list = [basis1_in, basis2_in]\n",
    "    \n",
    "    dimensionless_learning = DimensionlessLearning(\n",
    "        df, input_list, output_coef, dimension_info, basis_list)\n",
    "    # dimensionless_learning.check_dimension(coef=[-1, 1])\n",
    "\n",
    "    # pattern search\n",
    "    r2, coef, coef_w = dimensionless_learning.fit_pattern_search(seed=seed)\n",
    "    if r2 > 0.8:\n",
    "        print('final r2', r2, coef.flatten(), coef_w)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    recover_coef1(seed=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PyDimension",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "904ec0901b1dab60cbb175cce6563014087aab52b2a683f993104952735b0829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
